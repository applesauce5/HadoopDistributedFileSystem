This project did not come without its challenges. All parts of the project interact in what may seem like a complex system, but becomes more trivial as the understanding of the implementation unfolds. Tied together using the Java RMI interface, we were able to enable communication between objects between to completely different machines on the same network. Through these connections we were able to understand how large files are divided into chunks, which are then distrubuted among DataNode servers. However, the current implementation does not take full advantage of this strategy as it is not completely "fault tolerant". If the NameNode dies, then everything breaks. In addition, the selection of DataNodes to pull data from is biased to a few servers. Not to mention, we do not employ the full functionality and potential of blockReports and heartbeats, as they are essential to the fault tolerant philosophy HDFS tries to preserve. However, learning about these faults provided great insight into the inner workings of the Distributed File Systems of today. Matthew Cho primarily worked on the Client and DataNode portion. Russel D. worked on the NameNode and google protobuf portion.
